prediction <- function(model, data) {
sample_prediction <- predict(model, newdata = data)
sample_probability <- predict(model, newdata = data, type= "prob")
# Ensure churn prediction is numeric (convert factor levels to 0/1)
churn_numeric <- as.numeric(as.character(sample_prediction))
return(list(Churn = churn_numeric, Probabilities = sample_probability))
}
# Read input CSV file
sample_data <- read.csv('input.csv')
# Initialize an empty list to store results
results <- data.frame(CustomerID = sample_data$CustomerID, Churn = integer(nrow(sample_data)),
Prob_0 = numeric(nrow(sample_data)), Prob_1 = numeric(nrow(sample_data)))
# Perform prediction for each row
for (i in 1:nrow(sample_data)) {
row_data <- sample_data[i, , drop=FALSE]  # Extract individual row as a dataframe
# Get predictions from models
rf_result <- prediction(rf_model, row_data)
dt_result <- prediction(dt_model, row_data)
xgb_result <- prediction(xgb_model, row_data)
# Compute final aggregated prediction
final_churn <- as.integer(round(mean(c(rf_result$Churn, dt_result$Churn, xgb_result$Churn))))  # Majority vote
final_probabilities <- (rf_result$Probabilities + dt_result$Probabilities + xgb_result$Probabilities) / 3  # Average probabilities
# Store results
results$Churn[i] <- final_churn
results$Prob_0[i] <- final_probabilities[i, 1]
results$Prob_1[i] <- final_probabilities[i, 2]
}
# Load models
rf_model <- readRDS("rf_model.rds")
xgb_model <- readRDS("xgb_model.rds")
dt_model <- readRDS("dt_model.rds")
# Read input CSV file
sample_data <- read.csv('input.csv', stringsAsFactors = FALSE)
# Function to predict churn and probabilities for a given model
prediction <- function(model, data) {
sample_prediction <- predict(model, newdata = data)
sample_probability <- predict(model, newdata = data, type = "prob")
# Ensure churn prediction is numeric (convert factor levels to 0/1)
churn_numeric <- as.numeric(as.character(sample_prediction))
return(list(Churn = churn_numeric, Probabilities = sample_probability))
}
# Ensure categorical variables match model training levels
process_row <- function(row) {
return(data.frame(
CustomerID = row$CustomerID,
Tenure = row$Tenure,
PreferredLoginDevice = factor(row$PreferredLoginDevice, levels = levels(rf_model$trainingData$PreferredLoginDevice)),
CityTier = row$CityTier,
WarehouseToHome = row$WarehouseToHome,
PreferredPaymentMode = factor(row$PreferredPaymentMode, levels = levels(rf_model$trainingData$PreferredPaymentMode)),
Gender = factor(row$Gender, levels = levels(rf_model$trainingData$Gender)),
HourSpendOnApp = row$HourSpendOnApp,
NumberOfDeviceRegistered = row$NumberOfDeviceRegistered,
PreferedOrderCat = factor(row$PreferedOrderCat, levels = levels(rf_model$trainingData$PreferedOrderCat)),
SatisfactionScore = row$SatisfactionScore,
MaritalStatus = factor(row$MaritalStatus, levels = levels(rf_model$trainingData$MaritalStatus)),
NumberOfAddress = row$NumberOfAddress,
Complain = row$Complain,
OrderAmountHikeFromlastYear = row$OrderAmountHikeFromlastYear,
CouponUsed = row$CouponUsed,
OrderCount = row$OrderCount,
DaySinceLastOrder = row$DaySinceLastOrder,
CashbackAmount = row$CashbackAmount
))
}
# Initialize an empty data frame to store results
results <- data.frame(CustomerID = sample_data$CustomerID, Churn = integer(nrow(sample_data)),
Prob_0 = numeric(nrow(sample_data)), Prob_1 = numeric(nrow(sample_data)))
# Perform prediction for each row
for (i in 1:nrow(sample_data)) {
row_data <- process_row(sample_data[i, , drop=FALSE])  # Process row like sample_data
# Get predictions from models
rf_result <- prediction(rf_model, row_data)
dt_result <- prediction(dt_model, row_data)
xgb_result <- prediction(xgb_model, row_data)
# Compute final aggregated prediction
final_churn <- as.integer(round(mean(c(rf_result$Churn, dt_result$Churn, xgb_result$Churn))))  # Majority vote
final_probabilities <- (rf_result$Probabilities + dt_result$Probabilities + xgb_result$Probabilities) / 3  # Average probabilities
# Store results
results$Churn[i] <- final_churn
results$Prob_0[i] <- final_probabilities[1]
results$Prob_1[i] <- final_probabilities[2]
}
# Function to predict churn and probability based on given model
prediction <- function(model, sample_data) {
sample_prediction <- predict(model, newdata = sample_data)
sample_probability <- predict(model, newdata = sample_data, type= "prob")
# Ensure churn prediction is numeric (convert factor levels to 0/1)
churn_numeric <- as.numeric(as.character(sample_prediction))
return(list(Churn = churn_numeric, Probabilities = sample_probability))
}
# Create sample data for prediction
sample_data <- data.frame(
CustomerID = 50001,
Tenure = 4,
PreferredLoginDevice = factor("Mobile Phone", levels = levels(df$PreferredLoginDevice)),
CityTier = 3,
WarehouseToHome = 6,
PreferredPaymentMode = factor("Debit Card", levels = levels(df$PreferredPaymentMode)),
Gender = factor("Female", levels = levels(df$Gender)),
HourSpendOnApp = 3,
NumberOfDeviceRegistered = 3,
PreferedOrderCat = factor("Laptop & Accessory", levels = levels(df$PreferedOrderCat)),
SatisfactionScore = 2,
MaritalStatus = factor("Single", levels = levels(df$MaritalStatus)),
NumberOfAddress = 9,
Complain = 1,
OrderAmountHikeFromlastYear = 11,
CouponUsed = 1,
OrderCount = 1,
DaySinceLastOrder = 5,
CashbackAmount = 160
)
# Get predictions from models
rf_result <- prediction(rf_model, sample_data)
dt_result <- prediction(dt_model, sample_data)
xgb_result <- prediction(xgb_model, sample_data)
# Compute final aggregated prediction
final_churn <- as.integer(round(mean(c(rf_result$Churn, dt_result$Churn, xgb_result$Churn))))  # Majority vote
final_probabilities <- (rf_result$Probabilities + dt_result$Probabilities + xgb_result$Probabilities) / 3  # Average probabilities
# Print final result
final_result <- data.frame(Churn = final_churn, Prob_0 = final_probabilities[,1], Prob_1 = final_probabilities[,2])
print(final_result)
# Load necessary libraries
library(readr)  # For reading CSV
library(dplyr)  # For data wrangling
# Read the input CSV file
input_data <- read_csv("input.csv")
# Placeholder for predictions
output_data <- data.frame()
# Process each row
for (i in 2:nrow(input_data)) {
row <- input_data[i, ]  # Extract row
# Convert categorical variables into factors using existing levels from the dataset
processed_row <- data.frame(
CustomerID = row$CustomerID,
Tenure = row$Tenure,
PreferredLoginDevice = factor(row$PreferredLoginDevice, levels = levels(df$PreferredLoginDevice)),
CityTier = row$CityTier,
WarehouseToHome = row$WarehouseToHome,
PreferredPaymentMode = factor(row$PreferredPaymentMode, levels = levels(df$PreferredPaymentMode)),
Gender = factor(row$Gender, levels = levels(df$Gender)),
HourSpendOnApp = row$HourSpendOnApp,
NumberOfDeviceRegistered = row$NumberOfDeviceRegistered,
PreferedOrderCat = factor(row$PreferedOrderCat, levels = levels(df$PreferedOrderCat)),
SatisfactionScore = row$SatisfactionScore,
MaritalStatus = factor(row$MaritalStatus, levels = levels(df$MaritalStatus)),
NumberOfAddress = row$NumberOfAddress,
Complain = row$Complain,
OrderAmountHikeFromlastYear = row$OrderAmountHikeFromlastYear,
CouponUsed = row$CouponUsed,
OrderCount = row$OrderCount,
DaySinceLastOrder = row$DaySinceLastOrder,
CashbackAmount = row$CashbackAmount
)
print(processed_row)
}
# Load necessary libraries
library(readr)  # For reading CSV
library(dplyr)  # For data wrangling
# Read the input CSV file
input_data <- read_csv("input.csv")
# Placeholder for predictions
output_data <- data.frame()
# Process each row
for (i in 1:nrow(input_data)) {
row <- input_data[i, ]  # Extract row
# Convert categorical variables into factors using existing levels from the dataset
processed_row <- data.frame(
CustomerID = row$CustomerID,
Tenure = row$Tenure,
PreferredLoginDevice = factor(row$PreferredLoginDevice, levels = levels(df$PreferredLoginDevice)),
CityTier = row$CityTier,
WarehouseToHome = row$WarehouseToHome,
PreferredPaymentMode = factor(row$PreferredPaymentMode, levels = levels(df$PreferredPaymentMode)),
Gender = factor(row$Gender, levels = levels(df$Gender)),
HourSpendOnApp = row$HourSpendOnApp,
NumberOfDeviceRegistered = row$NumberOfDeviceRegistered,
PreferedOrderCat = factor(row$PreferedOrderCat, levels = levels(df$PreferedOrderCat)),
SatisfactionScore = row$SatisfactionScore,
MaritalStatus = factor(row$MaritalStatus, levels = levels(df$MaritalStatus)),
NumberOfAddress = row$NumberOfAddress,
Complain = row$Complain,
OrderAmountHikeFromlastYear = row$OrderAmountHikeFromlastYear,
CouponUsed = row$CouponUsed,
OrderCount = row$OrderCount,
DaySinceLastOrder = row$DaySinceLastOrder,
CashbackAmount = row$CashbackAmount
)
print(processed_row)
}
# Load necessary libraries
library(readr)  # For reading CSV
library(dplyr)  # For data wrangling
# Read the input CSV file
input_data <- read_csv("input.csv")
# Placeholder for predictions
output_data <- data.frame()
# Process each row
for (i in 1:nrow(input_data)) {
row <- input_data[i, ]  # Extract row
# Convert categorical variables into factors using existing levels from the dataset
processed_row <- data.frame(
CustomerID = row$CustomerID,
Tenure = row$Tenure,
PreferredLoginDevice = factor(row$PreferredLoginDevice, levels = levels(df$PreferredLoginDevice)),
CityTier = row$CityTier,
WarehouseToHome = row$WarehouseToHome,
PreferredPaymentMode = factor(row$PreferredPaymentMode, levels = levels(df$PreferredPaymentMode)),
Gender = factor(row$Gender, levels = levels(df$Gender)),
HourSpendOnApp = row$HourSpendOnApp,
NumberOfDeviceRegistered = row$NumberOfDeviceRegistered,
PreferedOrderCat = factor(row$PreferedOrderCat, levels = levels(df$PreferedOrderCat)),
SatisfactionScore = row$SatisfactionScore,
MaritalStatus = factor(row$MaritalStatus, levels = levels(df$MaritalStatus)),
NumberOfAddress = row$NumberOfAddress,
Complain = row$Complain,
OrderAmountHikeFromlastYear = row$OrderAmountHikeFromlastYear,
CouponUsed = row$CouponUsed,
OrderCount = row$OrderCount,
DaySinceLastOrder = row$DaySinceLastOrder,
CashbackAmount = row$CashbackAmount
)
processed_row
}
sample_data
# Load models
rf_model <- readRDS("rf_model.rds")
xgb_model <- readRDS("xgb_model.rds")
dt_model <- readRDS("dt_model.rds")
# Extract factor levels from one of the trained models
train_data <- rf_model$trainingData  # Extract the training dataset from the model
# Function to predict churn and probabilities
prediction <- function(model, data) {
churn_pred <- predict(model, newdata = data)
churn_prob <- predict(model, newdata = data, type = "prob")
# Convert churn prediction to numeric (handle factor levels)
churn_numeric <- as.numeric(as.character(churn_pred))
return(list(Churn = churn_numeric, Probabilities = churn_prob))
}
# Function to get final predictions using ensemble models
testData <- function(data) {
rf_result <- prediction(rf_model, data)
dt_result <- prediction(dt_model, data)
xgb_result <- prediction(xgb_model, data)
# Aggregate predictions
final_churn <- as.integer(round(mean(c(rf_result$Churn, dt_result$Churn, xgb_result$Churn))))  # Majority vote
final_probabilities <- (rf_result$Probabilities + dt_result$Probabilities + xgb_result$Probabilities) / 3  # Average probabilities
# Return final result as dataframe
return(data.frame(Churn = final_churn, Prob_0 = final_probabilities[,1], Prob_1 = final_probabilities[,2]))
}
# Load required libraries
library(readr)
library(dplyr)
# Source the prediction function
source("testData.R")
# Read input CSV
input_data <- read_csv("input.csv")
# Function to process categorical variables dynamically
process_row <- function(row, ref_data) {
return(data.frame(
CustomerID = row$CustomerID,
Tenure = row$Tenure,
PreferredLoginDevice = factor(row$PreferredLoginDevice, levels = levels(ref_data$PreferredLoginDevice)),
CityTier = row$CityTier,
WarehouseToHome = row$WarehouseToHome,
PreferredPaymentMode = factor(row$PreferredPaymentMode, levels = levels(ref_data$PreferredPaymentMode)),
Gender = factor(row$Gender, levels = levels(ref_data$Gender)),
HourSpendOnApp = row$HourSpendOnApp,
NumberOfDeviceRegistered = row$NumberOfDeviceRegistered,
PreferedOrderCat = factor(row$PreferedOrderCat, levels = levels(ref_data$PreferedOrderCat)),
SatisfactionScore = row$SatisfactionScore,
MaritalStatus = factor(row$MaritalStatus, levels = levels(ref_data$MaritalStatus)),
NumberOfAddress = row$NumberOfAddress,
Complain = row$Complain,
OrderAmountHikeFromlastYear = row$OrderAmountHikeFromlastYear,
CouponUsed = row$CouponUsed,
OrderCount = row$OrderCount,
DaySinceLastOrder = row$DaySinceLastOrder,
CashbackAmount = row$CashbackAmount
))
}
# Use the training data stored in the model to set factor levels
df <- rf_model$trainingData  # Get training data from the model
# Store results
output_data <- data.frame()
# Process each row
for (i in 1:nrow(input_data)) {
row <- input_data[i, ]  # Extract row
processed_row <- process_row(row, df)  # Convert categorical variables
# Get prediction
prediction_result <- testData(processed_row)
# Append result
output_data <- rbind(output_data, cbind(CustomerID = row$CustomerID, prediction_result))
}
# Load required libraries
library(readr)
library(dplyr)
# Source the prediction function
source("testData.R")
# Read input CSV
input_data <- read_csv("input.csv")
# Extract training data from model, removing `.outcome` column
df <- rf_model$trainingData[, -which(names(rf_model$trainingData) == ".outcome")]
# Function to process categorical variables dynamically
process_row <- function(row, ref_data) {
return(data.frame(
CustomerID = row$CustomerID,
Tenure = row$Tenure,
PreferredLoginDevice = factor(row$PreferredLoginDevice, levels = levels(ref_data$PreferredLoginDevice), exclude = NULL),
CityTier = row$CityTier,
WarehouseToHome = row$WarehouseToHome,
PreferredPaymentMode = factor(row$PreferredPaymentMode, levels = levels(ref_data$PreferredPaymentMode), exclude = NULL),
Gender = factor(row$Gender, levels = levels(ref_data$Gender), exclude = NULL),
HourSpendOnApp = row$HourSpendOnApp,
NumberOfDeviceRegistered = row$NumberOfDeviceRegistered,
PreferedOrderCat = factor(row$PreferedOrderCat, levels = levels(ref_data$PreferedOrderCat), exclude = NULL),
SatisfactionScore = row$SatisfactionScore,
MaritalStatus = factor(row$MaritalStatus, levels = levels(ref_data$MaritalStatus), exclude = NULL),
NumberOfAddress = row$NumberOfAddress,
Complain = row$Complain,
OrderAmountHikeFromlastYear = row$OrderAmountHikeFromlastYear,
CouponUsed = row$CouponUsed,
OrderCount = row$OrderCount,
DaySinceLastOrder = row$DaySinceLastOrder,
CashbackAmount = row$CashbackAmount
))
}
# Store results
output_data <- data.frame()
# Process each row
for (i in 1:nrow(input_data)) {
row <- input_data[i, ]  # Extract row
processed_row <- process_row(row, df) %>% drop_na()  # Convert categorical variables and remove NA
if (nrow(processed_row) > 0) {  # Ensure the row is not empty
# Get prediction
prediction_result <- testData(processed_row)
# Append result
output_data <- rbind(output_data, cbind(CustomerID = row$CustomerID, prediction_result))
}
}
# Save to output.csv
write_csv(output_data, "output.csv")
print("Predictions saved to output.csv")
output_data
# Load required libraries
library(readr)
library(dplyr)
# Source the prediction function
source("testData.R")
# Read input CSV
input_data <- read_csv("input.csv")
# Extract training data from model, removing `.outcome` column
df <- rf_model$trainingData[, -which(names(rf_model$trainingData) == ".outcome")]
# Function to process categorical variables dynamically
process_row <- function(row, ref_data) {
return(data.frame(
CustomerID = row$CustomerID,
Tenure = row$Tenure,
PreferredLoginDevice = factor(row$PreferredLoginDevice, levels = levels(ref_data$PreferredLoginDevice), exclude = NULL),
CityTier = row$CityTier,
WarehouseToHome = row$WarehouseToHome,
PreferredPaymentMode = factor(row$PreferredPaymentMode, levels = levels(ref_data$PreferredPaymentMode), exclude = NULL),
Gender = factor(row$Gender, levels = levels(ref_data$Gender), exclude = NULL),
HourSpendOnApp = row$HourSpendOnApp,
NumberOfDeviceRegistered = row$NumberOfDeviceRegistered,
PreferedOrderCat = factor(row$PreferedOrderCat, levels = levels(ref_data$PreferedOrderCat), exclude = NULL),
SatisfactionScore = row$SatisfactionScore,
MaritalStatus = factor(row$MaritalStatus, levels = levels(ref_data$MaritalStatus), exclude = NULL),
NumberOfAddress = row$NumberOfAddress,
Complain = row$Complain,
OrderAmountHikeFromlastYear = row$OrderAmountHikeFromlastYear,
CouponUsed = row$CouponUsed,
OrderCount = row$OrderCount,
DaySinceLastOrder = row$DaySinceLastOrder,
CashbackAmount = row$CashbackAmount
))
}
# Store results
output_data <- data.frame()
# Process each row
for (i in 1:nrow(input_data)) {
row <- input_data[i, ]  # Extract row
processed_row <- process_row(row, df) %>% drop_na()  # Convert categorical variables and remove NA
if (nrow(processed_row) > 0) {  # Ensure the row is not empty
# Get prediction
prediction_result <- testData(processed_row)
# Append result
output_data <- rbind(output_data, cbind(CustomerID = row$CustomerID, prediction_result))
}
}
# Save to output.csv
write_csv(output_data, "output.csv")
output_data
# Save to output.csv
write_csv(output_data, "output.csv")
print("Predictions saved to output.csv")
rf_model <- readRDS("models/rf_model.rds")
xgb_model <- readRDS("models/xgb_model.rds")
rf_model <- readRDS("models/rf_model.rds")
xgb_model <- readRDS("models/xgb_model.rds")
dt_model <- readRDS("models/dt_model.rds")
read.csv("data/training_dataset.csv")
input_data <- read_csv("data/input.csv")
write_csv(output_data, "data/output.csv")
rf_model <- readRDS("models/rf_model.rds")
library(tidyr)
# Performance metrics for trained models
compute_metrics <- function(conf_matrix) {
TP <- conf_matrix$table[2, 2]  # True Positives
FP <- conf_matrix$table[1, 2]  # False Positives
FN <- conf_matrix$table[2, 1]  # False Negatives
TN <- conf_matrix$table[1, 1]  # True Negatives
Accuracy <- (TP + TN) / sum(conf_matrix$table)
Precision <- TP / (TP + FP)
Recall <- TP / (TP + FN)
F1_Score <- 2 * (Precision * Recall) / (Precision + Recall)
Jaccard <- TP / (TP + FP + FN)
print(paste("Accuracy: ", Accuracy))
print(paste("Precision: ", Precision))
print(paste("Recall: ", Recall))
print(paste("F1 Score: ", F1_Score))
print(paste("Jaccard Index: ", Jaccard))
}
# DT model
conf_matrix1<-confusion_matrix(dt_model, testData)
# test-train split
set.seed(123)
trainIndex <- createDataPartition(df$Churn, p=0.8, list=FALSE)
# load packages
library(tidyverse)
library(caret)
library(xgboost)
library(ROSE)
library(e1071)
# Load Data
df <- read.csv("data/training_dataset.csv")
# Display Basic Info
print(dim(df))
# data pre processing
# Convert categorical variables to factors
df <- df %>% mutate_if(is.character, as.factor)
# Handling Missing Values
df <- df %>% drop_na()
# Encode Categorical Variables
df$Churn <- as.factor(df$Churn)
# test-train split
set.seed(123)
trainIndex <- createDataPartition(df$Churn, p=0.8, list=FALSE)
trainData <- df[trainIndex, ]
testData <- df[-trainIndex, ]
# load models
rf_model <- readRDS("models/rf_model.rds")
xgb_model <- readRDS("models/xgb_model.rds")
dt_model <- readRDS("models/dt_model.rds")
#function for confusion matrix
confusion_matrix<-function(model, testData){
y_pred <- predict(model, newdata=testData)
conf_matrix <- confusionMatrix(y_pred, as.factor(testData$Churn))
return (conf_matrix)
}
# Performance metrics for trained models
compute_metrics <- function(conf_matrix) {
TP <- conf_matrix$table[2, 2]  # True Positives
FP <- conf_matrix$table[1, 2]  # False Positives
FN <- conf_matrix$table[2, 1]  # False Negatives
TN <- conf_matrix$table[1, 1]  # True Negatives
Accuracy <- (TP + TN) / sum(conf_matrix$table)
Precision <- TP / (TP + FP)
Recall <- TP / (TP + FN)
F1_Score <- 2 * (Precision * Recall) / (Precision + Recall)
Jaccard <- TP / (TP + FP + FN)
print(paste("Accuracy: ", Accuracy))
print(paste("Precision: ", Precision))
print(paste("Recall: ", Recall))
print(paste("F1 Score: ", F1_Score))
print(paste("Jaccard Index: ", Jaccard))
}
# DT model
conf_matrix1<-confusion_matrix(dt_model, testData)
compute_metrics(conf_matrix1)
#RF model
conf_matrix2<-confusion_matrix(rf_model, testData)
compute_metrics(conf_matrix2)
#XGBoost model
conf_matrix3<-confusion_matrix(xgb_model, testData)
compute_metrics(conf_matrix3)
conf_matrix1
# function to plot feature importance
plot_feature_importance <- function(model) {
if ("randomForest" %in% class(model)) {
importance_df <- as.data.frame(importance(model))
importance_df$Feature <- rownames(importance_df)
importance_df <- importance_df %>% arrange(desc(MeanDecreaseGini))
} else if ("train" %in% class(model)) {
importance_df <- varImp(model)$importance
importance_df$Feature <- rownames(importance_df)
importance_df <- importance_df %>% arrange(desc(Overall))
} else {
stop("Model type not trained for feature importance extraction")
}
ggplot(importance_df, aes(x = reorder(Feature, desc(importance_df[,1])), y = importance_df[,1])) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +xlab("Test Attribute") +
ylab("Feature Importance") +
ggtitle(paste("Feature Importance -", model)) +
theme_minimal()
}
plot_feature_importance(dt_model)
plot_feature_importance(rf_model)
plot_feature_importance(rf_model)
plot_feature_importance(xgb_model)
